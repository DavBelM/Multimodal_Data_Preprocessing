{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing and Feature Extraction\n",
    "This notebook loads member images, applies augmentations, and extracts features for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Display Sample Pictures of Each Member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "image_dir = Path('data/images')\n",
    "\n",
    "# Get all image files\n",
    "image_files = sorted(list(image_dir.glob('*.jpeg')) + list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png')))\n",
    "\n",
    "# Extract member names\n",
    "members = sorted(list(set([f.stem.split('_')[0] for f in image_files])))\n",
    "print(f\"Members found: {members}\")\n",
    "print(f\"Total images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information without plotting (to save resources)\n",
    "print(\"\\nImage Details:\")\n",
    "for img_path in image_files:\n",
    "    img = Image.open(img_path)\n",
    "    print(f\"{img_path.name}: Size={img.size}, Mode={img.mode}\")\n",
    "\n",
    "print(\"\\nSkipping visualization - only extracting features to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply Augmentations to Images\n",
    "We'll apply the following augmentations:\n",
    "- Rotation (90°, 180°, 270°)\n",
    "- Horizontal and Vertical Flipping\n",
    "- Grayscale conversion\n",
    "- Random rotation (-30° to 30°)\n",
    "- Brightness adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentations(image_path):\n",
    "    \"\"\"\n",
    "    Apply various augmentations to an image and return augmented versions\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    augmentations = {\n",
    "        'original': img_array,\n",
    "        'rotate_90': np.array(img.rotate(90, expand=True)),\n",
    "        'rotate_180': np.array(img.rotate(180)),\n",
    "        'rotate_270': np.array(img.rotate(270, expand=True)),\n",
    "        'flip_horizontal': np.array(img.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "        'flip_vertical': np.array(img.transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "        'grayscale': np.array(img.convert('L')),\n",
    "        'rotate_random': np.array(img.rotate(np.random.randint(-30, 30))),\n",
    "    }\n",
    "    \n",
    "    return augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip visualization of augmentations - only extracting features\n",
    "print(\"Skipping augmentation visualization - only extracting features to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Image Features\n",
    "We'll extract multiple types of features:\n",
    "- Color histograms (RGB)\n",
    "- Grayscale histogram\n",
    "- Statistical features (mean, std, min, max)\n",
    "- Edge features using Canny edge detection\n",
    "- HOG (Histogram of Oriented Gradients) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "def extract_color_histogram(img_array, bins=32):\n",
    "    \"\"\"\n",
    "    Extract color histogram features for each channel\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    if len(img_array.shape) == 3:  # Color image\n",
    "        for i in range(3):  # RGB channels\n",
    "            hist, _ = np.histogram(img_array[:, :, i], bins=bins, range=(0, 256))\n",
    "            hist = hist / hist.sum()  # Normalize\n",
    "            features.extend(hist)\n",
    "    else:  # Grayscale\n",
    "        hist, _ = np.histogram(img_array, bins=bins, range=(0, 256))\n",
    "        hist = hist / hist.sum()\n",
    "        features.extend(hist)\n",
    "        # Pad with zeros to match RGB size\n",
    "        features.extend([0] * (bins * 2))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_statistical_features(img_array):\n",
    "    \"\"\"\n",
    "    Extract statistical features from image\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    if len(img_array.shape) == 3:  # Color image\n",
    "        for i in range(3):\n",
    "            channel = img_array[:, :, i]\n",
    "            features.extend([\n",
    "                np.mean(channel),\n",
    "                np.std(channel),\n",
    "                np.min(channel),\n",
    "                np.max(channel),\n",
    "                np.median(channel)\n",
    "            ])\n",
    "    else:  # Grayscale\n",
    "        features.extend([\n",
    "            np.mean(img_array),\n",
    "            np.std(img_array),\n",
    "            np.min(img_array),\n",
    "            np.max(img_array),\n",
    "            np.median(img_array)\n",
    "        ])\n",
    "        # Pad with zeros\n",
    "        features.extend([0] * 10)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_edge_features(img_array):\n",
    "    \"\"\"\n",
    "    Extract edge detection features using Canny\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_array\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Extract features from edges\n",
    "    features = [\n",
    "        np.sum(edges > 0) / edges.size,  # Edge density\n",
    "        np.mean(edges),\n",
    "        np.std(edges)\n",
    "    ]\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_hog_features(img_array, resize_shape=(128, 128)):\n",
    "    \"\"\"\n",
    "    Extract HOG (Histogram of Oriented Gradients) features\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_array\n",
    "    \n",
    "    # Resize for consistent feature size\n",
    "    resized = cv2.resize(gray, resize_shape)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    fd = hog(resized, orientations=9, pixels_per_cell=(8, 8),\n",
    "             cells_per_block=(2, 2), visualize=False)\n",
    "    \n",
    "    # Return first 100 features to keep size manageable\n",
    "    return fd[:100].tolist()\n",
    "\n",
    "def extract_all_features(img_path, augmentation_type='original'):\n",
    "    \"\"\"\n",
    "    Extract all features from an image\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Apply augmentation if needed\n",
    "    if augmentation_type != 'original':\n",
    "        augmented = apply_augmentations(img_path)\n",
    "        img_array = augmented.get(augmentation_type, img_array)\n",
    "    \n",
    "    # Extract all feature types\n",
    "    features = {\n",
    "        'image_name': img_path.name,\n",
    "        'member_name': img_path.stem.split('_')[0],\n",
    "        'expression': '_'.join(img_path.stem.split('_')[1:]),\n",
    "        'augmentation': augmentation_type,\n",
    "        'image_width': img.size[0],\n",
    "        'image_height': img.size[1],\n",
    "    }\n",
    "    \n",
    "    # Color histogram features\n",
    "    hist_features = extract_color_histogram(img_array)\n",
    "    for i, val in enumerate(hist_features):\n",
    "        features[f'hist_{i}'] = val\n",
    "    \n",
    "    # Statistical features\n",
    "    stat_features = extract_statistical_features(img_array)\n",
    "    stat_names = []\n",
    "    for channel in ['r', 'g', 'b']:\n",
    "        stat_names.extend([f'{channel}_mean', f'{channel}_std', f'{channel}_min', \n",
    "                          f'{channel}_max', f'{channel}_median'])\n",
    "    for name, val in zip(stat_names, stat_features):\n",
    "        features[name] = val\n",
    "    \n",
    "    # Edge features\n",
    "    edge_features = extract_edge_features(img_array)\n",
    "    features['edge_density'] = edge_features[0]\n",
    "    features['edge_mean'] = edge_features[1]\n",
    "    features['edge_std'] = edge_features[2]\n",
    "    \n",
    "    # HOG features\n",
    "    hog_features = extract_hog_features(img_array)\n",
    "    for i, val in enumerate(hog_features):\n",
    "        features[f'hog_{i}'] = val\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Features for All Images and Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all images and their augmentations\n",
    "all_features = []\n",
    "\n",
    "augmentation_types = ['original', 'rotate_90', 'rotate_180', 'rotate_270', \n",
    "                     'flip_horizontal', 'flip_vertical', 'grayscale', 'rotate_random']\n",
    "\n",
    "print(\"Extracting features from images...\")\n",
    "for img_path in image_files:\n",
    "    print(f\"Processing: {img_path.name}\")\n",
    "    \n",
    "    for aug_type in augmentation_types:\n",
    "        try:\n",
    "            features = extract_all_features(img_path, aug_type)\n",
    "            all_features.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error with {aug_type}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTotal feature vectors extracted: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Features to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(all_features)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'image_features.csv'\n",
    "features_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Features saved to: {output_path}\")\n",
    "print(f\"Shape: {features_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(features_df.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total images processed: {len(image_files)}\")\n",
    "print(f\"Total augmentations per image: {len(augmentation_types)}\")\n",
    "print(f\"Total feature vectors: {len(features_df)}\")\n",
    "print(f\"Features per vector: {len(features_df.columns)}\")\n",
    "print(f\"\\nMembers: {', '.join(members)}\")\n",
    "print(f\"\\nImages per member:\")\n",
    "print(features_df[features_df['augmentation'] == 'original']['member_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display info about the saved CSV\n",
    "print(\"\\nColumn names in image_features.csv:\")\n",
    "print(\"-\" * 80)\n",
    "for i, col in enumerate(features_df.columns, 1):\n",
    "    print(f\"{i:3d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal columns: {len(features_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
